{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ComfyUI QuickStart üìì\n",
        "\n",
        "> Minimal, config-driven installer for ComfyUI models and custom nodes.\n",
        "\n",
        "---\n",
        "30-python3.12-cuda12.1.1-torch2.5.1 template and use it in the Jupyter Notebook (port: 8888). <br>\n",
        "Link to template:  [ComfyUI v.0.3.30](https://runpod.io/console/deploy?template=fnox0jr8pw&ref=9n2q5pa8)\n",
        "Remember to Increase Pod Volumne to above 60gbs and 170gbs for ephemeral \n",
        ")\n",
        "This notebook is designed to be:\n",
        "- Config-driven (add HF/CivitAI/custom nodes in one CONFIG object)\n",
        "- Robust (retries, clear logs, token-aware)\n",
        "- Portable (no hardcoded model lists)\n",
        "\n",
        "Edit CONFIG, run Apply, verify. That's it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokens and Config\n",
        "# Fill in tokens or leave empty to download public assets anonymously\n",
        "# TODO: get as env variables\n",
        "HF_TOKEN = \"\"\n",
        "CIVITAI_TOKEN = \"\"\n",
        "\n",
        "# UI\n",
        "SHOW_PROGRESS = True  # stream command output and show curl progress bars (WIP)\n",
        "DRY_RUN = False       # set True to print plan without downloading\n",
        "VALIDATE_SIZES = False  # attempt to fetch sizes before downloading (slower)\n",
        "SKIP_EXISTING = True    # skip files that already exist (size > 0)\n",
        "INSTALL_NODE_REQUIREMENTS = True  # install requirements.txt in cloned custom nodes if present\n",
        "\n",
        "# Config-driven downloads\n",
        "CONFIG = {\n",
        "    # HuggingFace: list of items with repo/file and destination dir\n",
        "    # dest can be a key in CONFIG[\"dirs\"] (recommended) or an absolute path\n",
        "    \"huggingface_models\": [\n",
        "        # FLUX.1-dev core\n",
        "        {\"repo\": \"black-forest-labs/FLUX.1-dev\", \"files\": [\"ae.safetensors\"], \"dest\": \"vae\"},\n",
        "        {\"repo\": \"black-forest-labs/FLUX.1-dev\", \"files\": [\"flux1-dev.safetensors\"], \"dest\": \"unet\"},\n",
        "        {\"repo\": \"comfyanonymous/flux_text_encoders\", \"files\": [\"t5xxl_fp16.safetensors\", \"clip_l.safetensors\"], \"dest\": \"clip\"},\n",
        "\n",
        "        # GGUF UNET (Fill)\n",
        "        {\"repo\": \"YarvixPA/FLUX.1-Fill-dev-GGUF\", \"files\": [\"flux1-fill-dev-Q6_K.gguf\"], \"revision\": \"ed1b97dfd7faedbeaac08635330dc3ed23e86ea1\", \"dest\": \"unet\"},\n",
        "\n",
        "        # Dual CLIP\n",
        "        {\"repo\": \"comfyanonymous/flux_text_encoders\", \"files\": [\"clip_l.safetensors\", \"t5xxl_fp16.safetensors\"], \"dest\": \"clip\"},\n",
        "\n",
        "        # CLIP Vision\n",
        "        {\"repo\": \"Comfy-Org/sigclip_vision_384\", \"files\": [\"sigclip_vision_patch14_384.safetensors\"], \"dest\": \"clip_vision\"},\n",
        "\n",
        "        # Style Model\n",
        "        {\"repo\": \"black-forest-labs/FLUX.1-Redux-dev\", \"files\": [\"flux1-redux-dev.safetensors\"], \"dest\": \"style_models\"},\n",
        "\n",
        "        # VAE (pinned revision)\n",
        "        {\"repo\": \"lovis93/testllm\", \"files\": [\"ae.safetensors\"], \"revision\": \"ed9cf1af7465cebca4649157f118e331cf2a084f\", \"dest\": \"vae\"},\n",
        "\n",
        "        # LoRA from HF\n",
        "        {\"repo\": \"ali-vilab/ACE_Plus\", \"files\": [\"portrait/comfyui_portrait_lora64.safetensors\"], \"dest\": \"loras\"},\n",
        "\n",
        "        # SAM2\n",
        "        {\"repo\": \"facebook/sam2-hiera-large\", \"files\": [\"sam2_hiera_large.pt\"], \"dest\": \"sam2\"},\n",
        "\n",
        "        # Optional CLIP variant (may be unavailable)\n",
        "        # {\"repo\": \"zer0int/CLIP-GmP-ViT-L-14\", \"files\": [\"ViT-L-14-TEXT-detail-improved-hiT-GmP-TE-only-HF.safetensors\"], \"dest\": \"clip\"},\n",
        "\n",
        "        # Optional: FLUX.1-Turbo-Alpha UNET\n",
        "        # {\"repo\": \"alimama-creative/FLUX.1-Turbo-Alpha\", \"files\": [\"diffusion_pytorch_model.safetensors\"], \"dest\": \"unet\"},\n",
        "    ],\n",
        "\n",
        "    # CivitAI: supply version IDs or model IDs; type determines destination\n",
        "    # You can also override destination (dest) and filename per-item\n",
        "    \"civitai_items\": [\n",
        "        # {\"id\": \"0000000\", \"type\": \"checkpoint\", \"filename\": \"example_mid.safetensors\"},\n",
        "        # {\"id\": \"0000000\", \"type\": \"lora\"},\n",
        "    ],\n",
        "\n",
        "    # Custom nodes: git repos to clone or update\n",
        "    \"custom_nodes\": [\n",
        "        {\"repo\": \"https://github.com/ltdrdata/ComfyUI-Manager.git\"},\n",
        "        # Add more as needed, e.g. Impact Pack:\n",
        "        # {\"repo\": \"https://github.com/ltdrdata/ComfyUI-Impact-Pack.git\"},\n",
        "    ],\n",
        "\n",
        "    # Base directories for ComfyUI\n",
        "    \"dirs\": {\n",
        "        \"checkpoints\": \"/workspace/ComfyUI/models/checkpoints\",\n",
        "        \"unet\": \"/workspace/ComfyUI/models/unet\",\n",
        "        \"clip\": \"/workspace/ComfyUI/models/clip\",\n",
        "        \"clip_vision\": \"/workspace/ComfyUI/models/clip_vision\",\n",
        "        \"style_models\": \"/workspace/ComfyUI/models/style_models\",\n",
        "        \"vae\": \"/workspace/ComfyUI/models/vae\",\n",
        "        \"loras\": \"/workspace/ComfyUI/models/loras\",\n",
        "        \"embeddings\": \"/workspace/ComfyUI/models/embeddings\",\n",
        "        \"sam2\": \"/workspace/ComfyUI/models/sam2\",\n",
        "        \"custom_nodes\": \"/workspace/ComfyUI/custom_nodes\",\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"‚úÖ CONFIG ready. Edit CONFIG above to suit your needs.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpers\n",
        "import os, subprocess, shutil, json, time, re\n",
        "import requests\n",
        "\n",
        "def run(cmd: str, timeout: int = 1800) -> tuple[bool, str]:\n",
        "    # For curl, show progress by not capturing output. For others, capture.\n",
        "    wants_stream = SHOW_PROGRESS and (cmd.strip().startswith(\"curl \") or \" curl \" in cmd)\n",
        "    if wants_stream:\n",
        "        print(f\"$ {cmd}\")\n",
        "        try:\n",
        "            p = subprocess.run(cmd, shell=True, text=True, timeout=timeout)\n",
        "            ok = (p.returncode == 0)\n",
        "            return ok, \"\"\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, f\"timeout after {timeout}s: {cmd}\"\n",
        "    else:\n",
        "        try:\n",
        "            p = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)\n",
        "            out = (p.stdout or '').strip()\n",
        "            err = (p.stderr or '').strip()\n",
        "            if p.returncode == 0:\n",
        "                if out:\n",
        "                    print(out)\n",
        "                return True, out\n",
        "            else:\n",
        "                if err:\n",
        "                    print(err)\n",
        "                return False, err\n",
        "        except subprocess.TimeoutExpired:\n",
        "            return False, f\"timeout after {timeout}s: {cmd}\"\n",
        "\n",
        "\n",
        "def ensure_dirs():\n",
        "    d = CONFIG.get(\"dirs\", {})\n",
        "    all_dirs = list(d.values())\n",
        "    if all_dirs:\n",
        "        run(\"mkdir -p \" + \" \".join(all_dirs))\n",
        "\n",
        "\n",
        "def ensure_hf_cli():\n",
        "    # CLI and faster transfer backend (shows progress)\n",
        "    run(\"pip install -q --upgrade huggingface_hub[cli] hf_transfer\")\n",
        "    os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
        "    # Create alias if only huggingface-cli exists\n",
        "    hf = shutil.which('hf') or shutil.which('huggingface-cli')\n",
        "    if not shutil.which('hf') and hf:\n",
        "        run(f\"ln -sf {hf} /usr/local/bin/hf || true\")\n",
        "    # Auth if token is set\n",
        "    if HF_TOKEN:\n",
        "        os.environ['HUGGINGFACE_HUB_TOKEN'] = HF_TOKEN\n",
        "        os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "        run(\"hf whoami || true\")\n",
        "\n",
        "\n",
        "def file_exists_nonempty(path: str) -> bool:\n",
        "    try:\n",
        "        return os.path.isfile(path) and os.path.getsize(path) > 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def hf_download(repo: str, files: list[str], dest: str, revision: str | None = None) -> None:\n",
        "    run(f\"mkdir -p '{dest}'\")\n",
        "    # Prefer curl for progress; fallback to hf CLI on errors\n",
        "    for fpath in files:\n",
        "        used_curl = False\n",
        "        rev = revision or \"main\"\n",
        "        url = f\"https://huggingface.co/{repo}/resolve/{rev}/{fpath}\"\n",
        "        out_path = os.path.join(dest, os.path.basename(fpath))\n",
        "        if SKIP_EXISTING and file_exists_nonempty(out_path):\n",
        "            print(f\"‚Ü™Ô∏è Skipping existing: {os.path.basename(out_path)}\")\n",
        "            continue\n",
        "        if SHOW_PROGRESS:\n",
        "            hdr = f\"-H 'Authorization: Bearer {HF_TOKEN}'\" if HF_TOKEN else \"\"\n",
        "            ok, _ = run(f\"curl -L --fail --retry 5 --retry-delay 2 --retry-all-errors -C - {hdr} --output '{out_path}' '{url}'\")\n",
        "            used_curl = True\n",
        "            if ok:\n",
        "                continue\n",
        "        # Fallback to hf CLI\n",
        "        ensure_hf_cli()\n",
        "        rev_flag = f\" --revision {revision}\" if revision else \"\"\n",
        "        ok, _ = run(f\"hf download {repo} {fpath}{rev_flag} --local-dir '{dest}'\")\n",
        "        if not ok:\n",
        "            print(f\"‚ùå HF download failed: {repo}::{fpath}{'@'+revision if revision else ''}{' via curl' if used_curl else ''}\")\n",
        "\n",
        "\n",
        "# CivitAI helpers\n",
        "SAFE_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.\"\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    return ''.join(c for c in name if c in SAFE_CHARS) or \"civitai_file\"\n",
        "\n",
        "\n",
        "def civitai_resolve_version(mid_or_vid: str, token: str | None) -> tuple[str | None, dict]:\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"} if token else {}\n",
        "    # Try as version id\n",
        "    r = requests.get(f\"https://civitai.com/api/v1/model-versions/{mid_or_vid}\", headers=headers, timeout=25)\n",
        "    if r.status_code == 200:\n",
        "        data = r.json()\n",
        "        return str(data.get(\"id\")), data\n",
        "    # Try as model id (get latest version)\n",
        "    r = requests.get(f\"https://civitai.com/api/v1/models/{mid_or_vid}\", headers=headers, timeout=25)\n",
        "    if r.status_code == 200:\n",
        "        m = r.json()\n",
        "        versions = m.get(\"modelVersions\") or []\n",
        "        if versions:\n",
        "            vid = str(versions[0].get(\"id\"))\n",
        "            rv = requests.get(f\"https://civitai.com/api/v1/model-versions/{vid}\", headers=headers, timeout=25)\n",
        "            return vid, (rv.json() if rv.status_code == 200 else {})\n",
        "    return None, {}\n",
        "\n",
        "\n",
        "def civitai_pick_file(version_data: dict) -> tuple[str | None, str]:\n",
        "    files = version_data.get(\"files\") or []\n",
        "    primary = next((f for f in files if f.get(\"primary\")), files[0] if files else None)\n",
        "    if not primary:\n",
        "        return None, \"\"\n",
        "    url = primary.get(\"downloadUrl\")\n",
        "    name = primary.get(\"name\") or \"\"\n",
        "    return url, name\n",
        "\n",
        "\n",
        "def civitai_dest_for_type(model_type: str) -> str:\n",
        "    t = (model_type or '').lower()\n",
        "    d = CONFIG.get('dirs', {})\n",
        "    if t in {\"lora\",\"locon\",\"lycoris\"}:\n",
        "        return d.get('loras')\n",
        "    if t in {\"textualinversion\",\"embedding\",\"textual_inversion\"}:\n",
        "        return d.get('embeddings')\n",
        "    return d.get('checkpoints')\n",
        "\n",
        "\n",
        "def civitai_download(item: dict):\n",
        "    vid_or_mid = str(item.get('id'))\n",
        "    token = CIVITAI_TOKEN or None\n",
        "    vid, data = civitai_resolve_version(vid_or_mid, token)\n",
        "    if not vid:\n",
        "        print(f\"‚ùå Could not resolve CivitAI id {vid_or_mid}\")\n",
        "        return\n",
        "    url, name = civitai_pick_file(data)\n",
        "    if not url:\n",
        "        print(f\"‚ùå No downloadUrl for version {vid}\")\n",
        "        return\n",
        "    model = data.get('model') or {}\n",
        "    mtype = item.get('type') or (model.get('type') if model else None)\n",
        "    dest = civitai_dest_for_type(mtype)\n",
        "    if not dest:\n",
        "        dest = CONFIG['dirs']['checkpoints']\n",
        "    # Derive short descriptive name\n",
        "    mname = (model.get('name') or 'civitai')\n",
        "    prefix = re.sub(r'[^A-Za-z0-9_-]+', '', mname)[:16] or 'civitai'\n",
        "    ext = ''.join(name.split('.')[-1:]) if '.' in name else 'safetensors'\n",
        "    filename = sanitize_filename(f\"{prefix}_{vid}.{ext}\")\n",
        "    run(f\"mkdir -p '{dest}'\")\n",
        "    dl = url\n",
        "    if 'civitai.com/api/download/models' in dl and token:\n",
        "        sep = '&' if '?' in dl else '?'\n",
        "        dl = f\"{dl}{sep}token={token}\"\n",
        "    ok, _ = run(f\"curl -L --fail --retry 5 --retry-delay 2 --output '{os.path.join(dest, filename)}' '{dl}'\")\n",
        "    if not ok:\n",
        "        print(f\"‚ùå Download failed for CivitAI {vid_or_mid}\")\n",
        "\n",
        "print(\"‚úÖ Helpers loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Refined Helpers v2 (robust retries, filenames, revisions)\n",
        "import math\n",
        "from typing import Optional, Tuple, Dict, Any\n",
        "\n",
        "def log(msg: str):\n",
        "    print(msg)\n",
        "\n",
        "def run(cmd: str, timeout: int = 1800) -> tuple[bool, str]:\n",
        "    print(f\"$ {cmd}\")\n",
        "    try:\n",
        "        p = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)\n",
        "        out = (p.stdout or '').strip()\n",
        "        err = (p.stderr or '').strip()\n",
        "        if p.returncode == 0:\n",
        "            if out:\n",
        "                print(out)\n",
        "            return True, out\n",
        "        else:\n",
        "            if err:\n",
        "                print(err)\n",
        "            return False, err\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return False, f\"timeout after {timeout}s: {cmd}\"\n",
        "\n",
        "\n",
        "def fetch_json(url: str, headers: dict | None = None, retries: int = 4, timeout: int = 25) -> tuple[bool, dict]:\n",
        "    headers = headers or {}\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            r = requests.get(url, headers=headers, timeout=timeout)\n",
        "            if r.status_code == 200:\n",
        "                return True, r.json()\n",
        "            if r.status_code in (429, 500, 502, 503, 504):\n",
        "                sleep_s = min(10, 1.5 * (i + 1))\n",
        "                time.sleep(sleep_s)\n",
        "                continue\n",
        "            return False, {}\n",
        "        except Exception:\n",
        "            sleep_s = min(10, 1.5 * (i + 1))\n",
        "            time.sleep(sleep_s)\n",
        "    return False, {}\n",
        "\n",
        "\n",
        "def ensure_hf_cli():\n",
        "    run(\"pip install -q --upgrade huggingface_hub[cli]\")\n",
        "    hf = shutil.which('hf') or shutil.which('huggingface-cli')\n",
        "    if not shutil.which('hf') and hf:\n",
        "        run(f\"ln -sf {hf} /usr/local/bin/hf || true\")\n",
        "    if HF_TOKEN:\n",
        "        os.environ['HUGGINGFACE_HUB_TOKEN'] = HF_TOKEN\n",
        "        os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "        run(\"hf whoami || true\")\n",
        "\n",
        "\n",
        "def hf_download(repo: str, files: list[str], dest: str, revision: Optional[str] = None) -> None:\n",
        "    ensure_hf_cli()\n",
        "    run(f\"mkdir -p '{dest}'\")\n",
        "    rev_flag = f\" --revision {revision}\" if revision else \"\"\n",
        "    for f in files:\n",
        "        ok, _ = run(f\"hf download {repo} {f}{rev_flag} --local-dir '{dest}'\")\n",
        "        if not ok:\n",
        "            print(f\"‚ùå HF download failed: {repo}::{f}{'@'+revision if revision else ''}\")\n",
        "\n",
        "\n",
        "SAFE_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_.\"\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    name = ''.join(c for c in name if c in SAFE_CHARS) or \"civitai_file\"\n",
        "    if len(name) > 100:\n",
        "        base, dot, ext = name.rpartition('.')\n",
        "        base = base[:90] if base else name[:90]\n",
        "        ext = ext if dot else 'safetensors'\n",
        "        name = f\"{base}.{ext}\"\n",
        "    return name\n",
        "\n",
        "\n",
        "def civitai_resolve_version(mid_or_vid: str, token: Optional[str]) -> tuple[Optional[str], dict]:\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"} if token else {}\n",
        "    ok, data = fetch_json(f\"https://civitai.com/api/v1/model-versions/{mid_or_vid}\", headers)\n",
        "    if ok and data.get(\"id\"):\n",
        "        return str(data[\"id\"]), data\n",
        "    ok, m = fetch_json(f\"https://civitai.com/api/v1/models/{mid_or_vid}\", headers)\n",
        "    if ok:\n",
        "        versions = m.get(\"modelVersions\") or []\n",
        "        if versions:\n",
        "            vid = str(versions[0].get(\"id\"))\n",
        "            ok2, vd = fetch_json(f\"https://civitai.com/api/v1/model-versions/{vid}\", headers)\n",
        "            return vid, (vd if ok2 else {})\n",
        "    return None, {}\n",
        "\n",
        "\n",
        "def civitai_pick_file(version_data: dict) -> tuple[Optional[str], str]:\n",
        "    files = version_data.get(\"files\") or []\n",
        "    # Prefer safetensors, then others\n",
        "    preferred = None\n",
        "    for fobj in files:\n",
        "        n = (fobj.get(\"name\") or \"\").lower()\n",
        "        if n.endswith(\".safetensors\"):\n",
        "            preferred = fobj\n",
        "            break\n",
        "    if not preferred and files:\n",
        "        preferred = files[0]\n",
        "    if not preferred:\n",
        "        return None, \"\"\n",
        "    return preferred.get(\"downloadUrl\"), preferred.get(\"name\") or \"\"\n",
        "\n",
        "\n",
        "def civitai_dest_for_type(model_type: Optional[str]) -> str:\n",
        "    t = (model_type or '').lower()\n",
        "    d = CONFIG.get('dirs', {})\n",
        "    if t in {\"lora\",\"locon\",\"lycoris\"}: return d.get('loras')\n",
        "    if t in {\"textualinversion\",\"embedding\",\"textual_inversion\"}: return d.get('embeddings')\n",
        "    return d.get('checkpoints')\n",
        "\n",
        "\n",
        "def civitai_download(item: dict):\n",
        "    vid_or_mid = str(item.get('id'))\n",
        "    token = CIVITAI_TOKEN or None\n",
        "    vid, data = civitai_resolve_version(vid_or_mid, token)\n",
        "    if not vid:\n",
        "        print(f\"‚ùå Could not resolve CivitAI id {vid_or_mid}\")\n",
        "        return\n",
        "    url, name = civitai_pick_file(data)\n",
        "    if not url:\n",
        "        print(f\"‚ùå No downloadUrl for version {vid}\")\n",
        "        return\n",
        "    model = data.get('model') or {}\n",
        "    mtype = item.get('type') or (model.get('type') if model else None)\n",
        "\n",
        "    # Destination resolution with override support\n",
        "    dest = item.get('dest')\n",
        "    if dest:\n",
        "        # dest can be a key in dirs or an absolute path\n",
        "        if not dest.startswith('/'):\n",
        "            dest = CONFIG['dirs'].get(dest, CONFIG['dirs']['checkpoints'])\n",
        "    else:\n",
        "        dest = civitai_dest_for_type(mtype)\n",
        "        if not dest:\n",
        "            dest = CONFIG['dirs']['checkpoints']\n",
        "\n",
        "    # Filename override or derived\n",
        "    override_name = item.get('filename')\n",
        "    if override_name:\n",
        "        filename = sanitize_filename(override_name)\n",
        "    else:\n",
        "        mname = (model.get('name') or 'civitai')\n",
        "        prefix = re.sub(r'[^A-Za-z0-9_-]+', '', mname)[:16] or 'civitai'\n",
        "        ext = (name.rsplit('.', 1)[-1] if '.' in name else 'safetensors')\n",
        "        filename = sanitize_filename(f\"{prefix}_{vid}.{ext}\")\n",
        "\n",
        "    run(f\"mkdir -p '{dest}'\")\n",
        "\n",
        "    # Token append on initial CivitAI URL only\n",
        "    dl = url\n",
        "    if 'civitai.com/api/download/models' in dl and token:\n",
        "        sep = '&' if '?' in dl else '?'\n",
        "        dl = f\"{dl}{sep}token={token}\"\n",
        "\n",
        "    # Resume and robust curl\n",
        "    ok, _ = run(\n",
        "        f\"curl -L --fail --retry 5 --retry-delay 2 --retry-all-errors -C - --output '{os.path.join(dest, filename)}' '{dl}'\"\n",
        "    )\n",
        "    if not ok:\n",
        "        print(f\"‚ùå Download failed for CivitAI {vid_or_mid}\")\n",
        "\n",
        "def normalize_model_dirs():\n",
        "    # Move any mistakenly created /workspace/<name> dirs into CONFIG['dirs'][name]\n",
        "    names = [\"checkpoints\",\"unet\",\"clip\",\"clip_vision\",\"style_models\",\"vae\",\"loras\",\"embeddings\",\"sam2\"]\n",
        "    for name in names:\n",
        "        src = f\"/workspace/{name}\"\n",
        "        dst = CONFIG.get('dirs', {}).get(name)\n",
        "        try:\n",
        "            if not dst:\n",
        "                continue\n",
        "            if os.path.abspath(src) == os.path.abspath(dst):\n",
        "                continue\n",
        "            if os.path.isdir(src):\n",
        "                os.makedirs(dst, exist_ok=True)\n",
        "                for entry in os.listdir(src):\n",
        "                    src_path = os.path.join(src, entry)\n",
        "                    dst_path = os.path.join(dst, entry)\n",
        "                    try:\n",
        "                        if os.path.isdir(src_path) and not os.path.exists(dst_path):\n",
        "                            shutil.move(src_path, dst_path)\n",
        "                        elif os.path.isfile(src_path) and not os.path.exists(dst_path):\n",
        "                            shutil.move(src_path, dst_path)\n",
        "                    except Exception as move_err:\n",
        "                        print(f\"‚ö†Ô∏è Move warning for {src_path} -> {dst_path}: {move_err}\")\n",
        "                # Try remove empty src\n",
        "                try:\n",
        "                    os.rmdir(src)\n",
        "                except Exception:\n",
        "                    pass\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Normalize warning for {name}: {e}\")\n",
        "\n",
        "print(\"‚úÖ Refined helpers loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config hotfix: normalize HF destinations and remove invalid FLUX.1-dev entries\n",
        "fixed = []\n",
        "for it in CONFIG.get(\"huggingface_models\", []):\n",
        "    repo = it.get(\"repo\", \"\")\n",
        "    files = list(it.get(\"files\") or [])\n",
        "    dest = it.get(\"dest\")\n",
        "    if repo == \"black-forest-labs/FLUX.1-dev\":\n",
        "        # Keep only the VAE file which is valid; drop missing UNET/encoders from this repo\n",
        "        files = [f for f in files if f == \"ae.safetensors\"]\n",
        "        if not files:\n",
        "            continue\n",
        "        it = {**it, \"files\": files, \"dest\": \"vae\"}\n",
        "    fixed.append(it)\n",
        "CONFIG[\"huggingface_models\"] = fixed\n",
        "\n",
        "print(\"HF models after cleanup:\")\n",
        "for it in CONFIG[\"huggingface_models\"]:\n",
        "    print(\" -\", it)\n",
        "\n",
        "print(\"‚úÖ Hotfix applied. Now run 'Apply Configuration v2'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply Configuration v2 (validation + revisions)\n",
        "print(\"Applying configuration (v2)...\")\n",
        "ensure_dirs()\n",
        "\n",
        "# Helper to resolve dest keys to absolute paths\n",
        "def resolve_dest(dest_key_or_path: str | None) -> str:\n",
        "    if not dest_key_or_path:\n",
        "        return CONFIG['dirs']['checkpoints']\n",
        "    if isinstance(dest_key_or_path, str) and dest_key_or_path.startswith(\"/\"):\n",
        "        return dest_key_or_path\n",
        "    return CONFIG['dirs'].get(dest_key_or_path, CONFIG['dirs']['checkpoints'])\n",
        "\n",
        "# Validate git presence for custom nodes\n",
        "have_git = shutil.which('git') is not None\n",
        "if not have_git and CONFIG.get('custom_nodes'):\n",
        "    print(\"‚ö†Ô∏è git not found; custom nodes cloning will be skipped.\")\n",
        "\n",
        "# HuggingFace models (support per-item revision)\n",
        "for item in CONFIG.get(\"huggingface_models\", []):\n",
        "    repo = item.get(\"repo\")\n",
        "    files = item.get(\"files\") or []\n",
        "    dest = resolve_dest(item.get(\"dest\"))\n",
        "    revision = item.get(\"revision\")\n",
        "    if not repo or not files:\n",
        "        print(f\"‚ö†Ô∏è Skipping invalid HF entry: {item}\")\n",
        "        continue\n",
        "    print(f\"‚û°Ô∏è HF: {repo}{'@'+revision if revision else ''} -> {dest}\")\n",
        "    hf_download(repo, files, dest, revision=revision)\n",
        "\n",
        "# CivitAI items (process smaller items first)\n",
        "items = CONFIG.get(\"civitai_items\", [])\n",
        "small_first = [it for it in items if str(it.get('type','')).lower() != 'checkpoint']\n",
        "checkpoints = [it for it in items if str(it.get('type','')).lower() == 'checkpoint']\n",
        "\n",
        "if small_first:\n",
        "    print(f\"‚û°Ô∏è CivitAI (LoRAs/Embeddings first): {len(small_first)} item(s)\")\n",
        "    for item in small_first:\n",
        "        try:\n",
        "            if 'id' not in item:\n",
        "                print(f\"‚ö†Ô∏è Skipping invalid CivitAI entry (missing id): {item}\")\n",
        "                continue\n",
        "            print(f\"   ‚Ä¢ {item}\")\n",
        "            civitai_download(item)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå CivitAI error: {e}\")\n",
        "\n",
        "if checkpoints:\n",
        "    print(f\"‚û°Ô∏è CivitAI (Checkpoints next): {len(checkpoints)} item(s)\")\n",
        "    for item in checkpoints:\n",
        "        try:\n",
        "            if 'id' not in item:\n",
        "                print(f\"‚ö†Ô∏è Skipping invalid CivitAI entry (missing id): {item}\")\n",
        "                continue\n",
        "            print(f\"   ‚Ä¢ {item}\")\n",
        "            civitai_download(item)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå CivitAI error: {e}\")\n",
        "\n",
        "# Custom nodes\n",
        "if CONFIG.get(\"custom_nodes\") and have_git:\n",
        "    base = resolve_dest('custom_nodes')\n",
        "    run(f\"mkdir -p '{base}'\")\n",
        "    for node in CONFIG['custom_nodes']:\n",
        "        repo = node.get('repo')\n",
        "        if not repo:\n",
        "            print(f\"‚ö†Ô∏è Skipping custom node without repo: {node}\")\n",
        "            continue\n",
        "        name = repo.rstrip('/').split('/')[-1].replace('.git','')\n",
        "        path = os.path.join(base, name)\n",
        "        if os.path.isdir(path):\n",
        "            print(f\"üîÑ Updating {name}\")\n",
        "            run(f\"cd '{path}' && git pull --ff-only | cat\")\n",
        "        else:\n",
        "            print(f\"‚¨áÔ∏è Cloning {name}\")\n",
        "            run(f\"git clone '{repo}' '{path}' | cat\")\n",
        "\n",
        "# Final normalization pass (if any tools wrote to /workspace/<name>)\n",
        "normalize_model_dirs()\n",
        "print(\"\\n‚úÖ Done (v2).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify Downloads\n",
        "import glob\n",
        "\n",
        "base = CONFIG.get('dirs', {})\n",
        "\n",
        "def list_dir(label, path, patterns=(\"*.safetensors\",\"*.pt\",\"*.ckpt\",\"*.bin\",\"*.gguf\")):\n",
        "    if not path:\n",
        "        return\n",
        "    files = []\n",
        "    for pat in patterns:\n",
        "        files.extend(glob.glob(os.path.join(path, pat)))\n",
        "    if files:\n",
        "        total = sum(os.path.getsize(f) for f in files) / (1024*1024)\n",
        "        print(f\"‚úÖ {label}: {len(files)} files, {total:.1f} MB\")\n",
        "        for f in sorted(files)[:10]:\n",
        "            sz = os.path.getsize(f)/(1024*1024)\n",
        "            print(f\" - {os.path.basename(f)} ({sz:.1f} MB)\")\n",
        "        if len(files) > 10:\n",
        "            print(f\" ... +{len(files)-10} more\")\n",
        "    else:\n",
        "        print(f\"‚ùå {label}: none\")\n",
        "\n",
        "list_dir(\"Checkpoints\", base.get('checkpoints'))\n",
        "list_dir(\"UNet\", base.get('unet'))\n",
        "list_dir(\"CLIP\", base.get('clip'))\n",
        "list_dir(\"CLIP Vision\", base.get('clip_vision'))\n",
        "list_dir(\"Style Models\", base.get('style_models'))\n",
        "list_dir(\"VAE\", base.get('vae'))\n",
        "list_dir(\"LoRAs\", base.get('loras'))\n",
        "list_dir(\"Embeddings\", base.get('embeddings'))\n",
        "list_dir(\"SAM2\", base.get('sam2'))\n",
        "\n",
        "print(\"\\nüîç Verification complete.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
